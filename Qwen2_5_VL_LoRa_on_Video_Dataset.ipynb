{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyN40eV2uZO/182cSGvc/JAZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b29e92a1cd944eb092f4ad8684ff9cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c428e2753de472788526e1dfe2141ac",
              "IPY_MODEL_eb7811a8c3bf42769612de98177415ea",
              "IPY_MODEL_d005197dad814cedb0af2995bb602296"
            ],
            "layout": "IPY_MODEL_288b6b4818134da3b739ff4062de4def"
          }
        },
        "8c428e2753de472788526e1dfe2141ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d48faf3a51a94588a8ecb88744c2d4fe",
            "placeholder": "​",
            "style": "IPY_MODEL_ed34c5300d6e4aa499696a06d579e39c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "eb7811a8c3bf42769612de98177415ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22ed257cbe5b4bc79aa74d6b3cde2282",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a7e2b8d529145d68442ee4d1620dee2",
            "value": 2
          }
        },
        "d005197dad814cedb0af2995bb602296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f0e5e66bd8849f08e241ec23358dd99",
            "placeholder": "​",
            "style": "IPY_MODEL_826cd4e090bc4b2cabdd6ea320aa4140",
            "value": " 2/2 [00:14&lt;00:00,  7.19s/it]"
          }
        },
        "288b6b4818134da3b739ff4062de4def": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d48faf3a51a94588a8ecb88744c2d4fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed34c5300d6e4aa499696a06d579e39c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22ed257cbe5b4bc79aa74d6b3cde2282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a7e2b8d529145d68442ee4d1620dee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f0e5e66bd8849f08e241ec23358dd99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "826cd4e090bc4b2cabdd6ea320aa4140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5717c6201aa247a990fa0e08f6e32ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78cca0a7e817417dbbe1559dcdd0d915",
              "IPY_MODEL_b4aa960cb8e2449b8b058ee079d137d5",
              "IPY_MODEL_4747944d87834e92a4b361641ceb3de1"
            ],
            "layout": "IPY_MODEL_eaba3d89eada49ca818a00057402a9f1"
          }
        },
        "78cca0a7e817417dbbe1559dcdd0d915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_469cc2059239470998a3453d421ceb21",
            "placeholder": "​",
            "style": "IPY_MODEL_50ea4fa919784889bcb8785759da36b7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b4aa960cb8e2449b8b058ee079d137d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c349cc2b4664392afb2a80401eab4f2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87ced173a46a477caa21d63aeba7a07c",
            "value": 2
          }
        },
        "4747944d87834e92a4b361641ceb3de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a1e1c2f73c64456992f9af0546c1550",
            "placeholder": "​",
            "style": "IPY_MODEL_45e126a7c4a84861a29dc78f32068d66",
            "value": " 2/2 [00:01&lt;00:00,  1.16it/s]"
          }
        },
        "eaba3d89eada49ca818a00057402a9f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "469cc2059239470998a3453d421ceb21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50ea4fa919784889bcb8785759da36b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c349cc2b4664392afb2a80401eab4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87ced173a46a477caa21d63aeba7a07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a1e1c2f73c64456992f9af0546c1550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45e126a7c4a84861a29dc78f32068d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "febffd5574234e9fb158defb3454bf9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edb7ca03364e44fb8a98521392ef99d2",
              "IPY_MODEL_6216d5f67cfc49708806ef92f6d84b87",
              "IPY_MODEL_c88805c938c541db886f2f358bf0a251"
            ],
            "layout": "IPY_MODEL_8ba571d316d7434ea4f12b7f75fa1e88"
          }
        },
        "edb7ca03364e44fb8a98521392ef99d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a07f042480ca4a27bb1b3196a694259e",
            "placeholder": "​",
            "style": "IPY_MODEL_d3002ff41b1e46f694e52ab370b5b6ad",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6216d5f67cfc49708806ef92f6d84b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638a1b5458e6493b803c0f0fb5909f9b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7907d548fff4c17b1f984a2c4366ed7",
            "value": 2
          }
        },
        "c88805c938c541db886f2f358bf0a251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ba47ac16ce14e368979ae6464138bad",
            "placeholder": "​",
            "style": "IPY_MODEL_071c401ed345426ca85989a20c2500fd",
            "value": " 2/2 [00:02&lt;00:00,  1.26s/it]"
          }
        },
        "8ba571d316d7434ea4f12b7f75fa1e88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a07f042480ca4a27bb1b3196a694259e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3002ff41b1e46f694e52ab370b5b6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "638a1b5458e6493b803c0f0fb5909f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7907d548fff4c17b1f984a2c4366ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ba47ac16ce14e368979ae6464138bad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "071c401ed345426ca85989a20c2500fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahedmomenzadeh/Qwen2.5_VL_video_QA_finetune/blob/main/Qwen2_5_VL_LoRa_on_Video_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers datasets accelerate peft torch torchvision bitsandbytes --quiet\n",
        "!pip install qwen-vl-utils --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1dnI0dz7MqG",
        "outputId": "16504844-afea-4466-bf49-0405f1ef0827"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.7/374.7 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m132.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.8.0 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "import requests\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "# Install required packages if they are not already installed.\n",
        "!pip install --upgrade transformers datasets accelerate peft torch torchvision bitsandbytes --quiet\n",
        "!pip install qwen-vl-utils[decord] --quiet\n",
        "\n",
        "# Hugging Face and PEFT imports\n",
        "from huggingface_hub import login\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "# Transformers and datasets imports\n",
        "from transformers import (\n",
        "    AutoProcessor,\n",
        "    AutoModelForVision2Seq,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    BitsAndBytesConfig,\n",
        "    default_data_collator\n",
        ")\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Qwen-VL utils for proper video processing\n",
        "from qwen_vl_utils import process_vision_info\n",
        "\n",
        "# 1. Login to Hugging Face hub (optional, but good practice)\n",
        "print(\"Login to Hugging Face Hub:\")\n",
        "# In a real script, you might handle this with an environment variable or token.\n",
        "# For this example, we'll assume a login has been handled if needed.\n",
        "# login()\n",
        "\n",
        "# 2. Use the user-specified local video file\n",
        "print(\"\\nUsing local video file...\")\n",
        "# --- CHANGE: Using the user-provided local video path ---\n",
        "downloaded_video_path = \"./video_girl_playing_music.mp4\"\n",
        "\n",
        "if not os.path.exists(downloaded_video_path):\n",
        "    print(f\"Error: Video file not found at {downloaded_video_path}\")\n",
        "    print(\"Please make sure the video file is uploaded to the correct path.\")\n",
        "    exit()\n",
        "else:\n",
        "    print(f\"Found video file: {downloaded_video_path}\")\n",
        "\n",
        "# Create a directory to store the dataset videos\n",
        "os.makedirs(\"videos_temporal_girl\", exist_ok=True)\n",
        "\n",
        "# 3. Manually create a QA dataset using the local video\n",
        "data = []\n",
        "num_samples = 3\n",
        "print(f\"\\nPreparing {num_samples} samples for temporal fine-tuning...\")\n",
        "\n",
        "# --- CHANGE: Updated answers to match the new video content ---\n",
        "answers = [\n",
        "    \"A girl is sitting in a chair outdoors and playing a musical instrument.\",\n",
        "    \"The video shows a girl playing music in a natural setting.\",\n",
        "    \"A musician is playing an instrument while seated in a chair surrounded by nature.\"\n",
        "]\n",
        "\n",
        "for i in range(num_samples):\n",
        "    video_filename = f\"video_girl_action_{i+1}.mp4\"\n",
        "    video_path_local = os.path.join(\"videos_temporal_girl\", video_filename)\n",
        "    shutil.copy(downloaded_video_path, video_path_local)\n",
        "    data.append({\n",
        "        \"video_path\": video_path_local,\n",
        "        \"question\": \"Describe the main action in the video.\",\n",
        "        \"answer\": answers[i]\n",
        "    })\n",
        "\n",
        "# Save the structured data to a JSONL file\n",
        "jsonl_path = \"qa_temporal_dataset_girl.jsonl\"\n",
        "with open(jsonl_path, \"w\") as f:\n",
        "    for entry in data:\n",
        "        f.write(json.dumps(entry) + \"\\n\")\n",
        "print(f\"Saved {len(data)} videos and temporal QA pairs to {jsonl_path}\")\n",
        "\n",
        "# 4. Load the processor and model\n",
        "model_id = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
        "\n",
        "# Define the quantization configuration for memory efficiency\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "print(\"\\nLoading processor and model with 4-bit quantization...\")\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
        "model = AutoModelForVision2Seq.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quantization_config,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# 5. Setup LoRA / PEFT configuration\n",
        "print(\"Configuring LoRA...\")\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "    inference_mode=False,\n",
        "    r=4,\n",
        "    lora_alpha=8,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
        ")\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "# Prepare the model for training\n",
        "model.config.use_cache = False\n",
        "model.gradient_checkpointing_enable()\n",
        "model.enable_input_require_grads()\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# 6. Define the PyTorch Dataset for loading and processing our data\n",
        "class VideoQADataset(Dataset):\n",
        "    \"\"\"\n",
        "    A PyTorch Dataset to load video-question-answer pairs, process them for\n",
        "    the Qwen2.5-VL model, and prepare them for training.\n",
        "    This version follows the official documentation by separating text templating\n",
        "    from vision processing using process_vision_info.\n",
        "    \"\"\"\n",
        "    def __init__(self, jsonl_file, processor):\n",
        "        self.processor = processor\n",
        "        with open(jsonl_file, \"r\") as f:\n",
        "            self.samples = [json.loads(line) for line in f]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "        video_path = sample[\"video_path\"]\n",
        "        question = sample[\"question\"]\n",
        "        answer = sample[\"answer\"]\n",
        "\n",
        "        # Create the conversation structure as expected by the processor.\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"video\",\n",
        "                        \"video\": video_path,  # Correct key: \"video\" instead of \"path\"\n",
        "                        \"fps\": 1,  # Sample at 4 FPS; adjust as needed\n",
        "                    },\n",
        "                    {\"type\": \"text\", \"text\": question},\n",
        "                ],\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": answer  # Simplified as string for the assistant response\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Apply chat template to get the text prompt (without vision info)\n",
        "        text = self.processor.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=False\n",
        "        )\n",
        "\n",
        "        # Extract vision inputs separately\n",
        "        image_inputs, video_inputs = process_vision_info(messages)\n",
        "\n",
        "        # Tokenize with vision inputs\n",
        "        inputs = self.processor(\n",
        "            text=[text],\n",
        "            images=image_inputs,\n",
        "            videos=video_inputs,\n",
        "            padding=False,  # No padding here; handled by collator if needed\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Squeeze to remove batch dim (since single example)\n",
        "        inputs = {k: v.squeeze(0) for k, v in inputs.items() if v is not None}\n",
        "\n",
        "        # Set labels\n",
        "        inputs[\"labels\"] = inputs[\"input_ids\"].clone()\n",
        "\n",
        "        # Mask labels for the prompt part (user + generation prompt)\n",
        "        prompt_messages = messages[:1]  # Only user message\n",
        "        prompt_text = self.processor.apply_chat_template(\n",
        "            prompt_messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "        prompt_image_inputs, prompt_video_inputs = process_vision_info(prompt_messages)\n",
        "        prompt_inputs = self.processor(\n",
        "            text=[prompt_text],\n",
        "            images=prompt_image_inputs,\n",
        "            videos=prompt_video_inputs,\n",
        "            padding=False,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        prompt_len = prompt_inputs[\"input_ids\"].shape[1]\n",
        "        inputs[\"labels\"][:prompt_len] = -100\n",
        "\n",
        "        return inputs\n",
        "\n",
        "# Instantiate the dataset\n",
        "train_dataset = VideoQADataset(jsonl_path, processor)\n",
        "\n",
        "# 7. Define Training Arguments and instantiate the Trainer\n",
        "# --- CHANGE: Updated output directory name ---\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./qwen_temporal_peft_finetuned_girl\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=1,\n",
        "    remove_unused_columns=False,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=not torch.cuda.is_bf16_supported(),\n",
        "    bf16=torch.cuda.is_bf16_supported(),\n",
        "    optim=\"adamw_8bit\",\n",
        "    seed=3407,\n",
        "    report_to=\"none\",  # Avoid external logging\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        ")\n",
        "\n",
        "# 8. Start Fine-tuning\n",
        "print(\"\\nStarting fine-tuning with the Trainer API...\")\n",
        "trainer.train()\n",
        "print(\"\\n✅ Fine-tuning completed successfully!\")\n",
        "\n",
        "# 9. Save the final LoRA adapter\n",
        "# --- CHANGE: Updated adapter directory name ---\n",
        "output_adapter_dir = \"qwen_peft_lora_adapter_temporal_girl\"\n",
        "print(f\"\\nSaving LoRA adapter to {output_adapter_dir}...\")\n",
        "trainer.save_model(output_adapter_dir)\n",
        "processor.save_pretrained(output_adapter_dir)\n",
        "print(\"Adapter and processor saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810,
          "referenced_widgets": [
            "b29e92a1cd944eb092f4ad8684ff9cd0",
            "8c428e2753de472788526e1dfe2141ac",
            "eb7811a8c3bf42769612de98177415ea",
            "d005197dad814cedb0af2995bb602296",
            "288b6b4818134da3b739ff4062de4def",
            "d48faf3a51a94588a8ecb88744c2d4fe",
            "ed34c5300d6e4aa499696a06d579e39c",
            "22ed257cbe5b4bc79aa74d6b3cde2282",
            "7a7e2b8d529145d68442ee4d1620dee2",
            "0f0e5e66bd8849f08e241ec23358dd99",
            "826cd4e090bc4b2cabdd6ea320aa4140"
          ]
        },
        "id": "Zkol5UazaubC",
        "outputId": "4dda5878-ee3e-473d-b178-f43809267bc8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login to Hugging Face Hub:\n",
            "\n",
            "Using local video file...\n",
            "Found video file: ./video_girl_playing_music.mp4\n",
            "\n",
            "Preparing 3 samples for temporal fine-tuning...\n",
            "Saved 3 videos and temporal QA pairs to qa_temporal_dataset_girl.jsonl\n",
            "\n",
            "Loading processor and model with 4-bit quantization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
            "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/modeling_auto.py:2199: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b29e92a1cd944eb092f4ad8684ff9cd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuring LoRA...\n",
            "trainable params: 1,843,200 || all params: 3,756,466,176 || trainable%: 0.0491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2669032860.py:226: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting fine-tuning with the Trainer API...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "qwen-vl-utils using decord to read video.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 02:03, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>6.691000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6.498800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>6.183600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.934200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>5.710700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Fine-tuning completed successfully!\n",
            "\n",
            "Saving LoRA adapter to qwen_peft_lora_adapter_temporal_girl...\n",
            "Adapter and processor saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
        "from peft import PeftModel\n",
        "from qwen_vl_utils import process_vision_info\n",
        "\n",
        "# Assuming the required packages are installed (as in the training script)\n",
        "# If not, uncomment the following:\n",
        "# !pip install --upgrade transformers accelerate peft torch torchvision bitsandbytes --quiet\n",
        "# !pip install qwen-vl-utils[decord] --quiet\n",
        "\n",
        "# Define paths and parameters\n",
        "model_id = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
        "adapter_dir = \"qwen_peft_lora_adapter_temporal_girl\"\n",
        "video_path = \"./video_girl_playing_music.mp4\"  # Same as in training\n",
        "question = \"Describe the main action in the video in 2 sentences.\"\n",
        "fps = 1  # Matching the training setting\n",
        "max_new_tokens = 128  # Adjust as needed for response length\n",
        "\n",
        "# Load the processor (from adapter dir or original; assumes it's saved there)\n",
        "processor = AutoProcessor.from_pretrained(adapter_dir, trust_remote_code=True)\n",
        "\n",
        "# Load the original base model\n",
        "print(\"Loading original model...\")\n",
        "original_model = AutoModelForVision2Seq.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "original_model.eval()\n",
        "\n",
        "# Load the fine-tuned model (base + LoRA adapter)\n",
        "print(\"Loading fine-tuned model...\")\n",
        "base_model = AutoModelForVision2Seq.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "finetuned_model = PeftModel.from_pretrained(\n",
        "    base_model,\n",
        "    adapter_dir,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "finetuned_model.eval()\n",
        "\n",
        "# Prepare the messages for inference\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"video\",\n",
        "                \"video\": video_path,\n",
        "                \"fps\": fps,\n",
        "            },\n",
        "            {\"type\": \"text\", \"text\": question},\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "# Function to generate response from a model\n",
        "def generate_response(model, processor, messages):\n",
        "    # Apply chat template\n",
        "    text = processor.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    # Process vision info\n",
        "    image_inputs, video_inputs = process_vision_info(messages)\n",
        "\n",
        "    # Prepare inputs\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        videos=video_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    inputs = inputs.to(model.device)\n",
        "\n",
        "    # Generate\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=False,  # Deterministic for comparison\n",
        "        )\n",
        "\n",
        "    # Trim and decode\n",
        "    generated_ids_trimmed = generated_ids[0, len(inputs[\"input_ids\"][0]):]\n",
        "    output_text = processor.decode(generated_ids_trimmed, skip_special_tokens=True)\n",
        "\n",
        "    return output_text\n",
        "\n",
        "# Get outputs\n",
        "print(\"\\nGenerating response from original model...\")\n",
        "original_output = generate_response(original_model, processor, messages)\n",
        "print(\"Original Model Output:\", original_output)\n",
        "\n",
        "print(\"\\nGenerating response from fine-tuned model...\")\n",
        "finetuned_output = generate_response(finetuned_model, processor, messages)\n",
        "print(\"Fine-Tuned Model Output:\", finetuned_output)\n",
        "\n",
        "# Optional: Compare\n",
        "print(\"\\nComparison:\")\n",
        "print(\"Original:\", original_output)\n",
        "print(\"Fine-Tuned:\", finetuned_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "5717c6201aa247a990fa0e08f6e32ca9",
            "78cca0a7e817417dbbe1559dcdd0d915",
            "b4aa960cb8e2449b8b058ee079d137d5",
            "4747944d87834e92a4b361641ceb3de1",
            "eaba3d89eada49ca818a00057402a9f1",
            "469cc2059239470998a3453d421ceb21",
            "50ea4fa919784889bcb8785759da36b7",
            "7c349cc2b4664392afb2a80401eab4f2",
            "87ced173a46a477caa21d63aeba7a07c",
            "4a1e1c2f73c64456992f9af0546c1550",
            "45e126a7c4a84861a29dc78f32068d66",
            "febffd5574234e9fb158defb3454bf9a",
            "edb7ca03364e44fb8a98521392ef99d2",
            "6216d5f67cfc49708806ef92f6d84b87",
            "c88805c938c541db886f2f358bf0a251",
            "8ba571d316d7434ea4f12b7f75fa1e88",
            "a07f042480ca4a27bb1b3196a694259e",
            "d3002ff41b1e46f694e52ab370b5b6ad",
            "638a1b5458e6493b803c0f0fb5909f9b",
            "f7907d548fff4c17b1f984a2c4366ed7",
            "0ba47ac16ce14e368979ae6464138bad",
            "071c401ed345426ca85989a20c2500fd"
          ]
        },
        "id": "mvlNsDP29xuv",
        "outputId": "1c0eb956-8593-4729-9df7-7d90a65a22f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading original model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5717c6201aa247a990fa0e08f6e32ca9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading fine-tuned model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "febffd5574234e9fb158defb3454bf9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating response from original model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Model Output: The main action in the video is a woman playing a ukulele on a grassy hillside with rolling hills and trees in the background. She is wearing a white dress and has long, wavy hair.\n",
            "\n",
            "Generating response from fine-tuned model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-Tuned Model Output: A woman stands on a grassy hill, playing an orange ukulele. She moves her head slightly and adjusts her hair as she plays.\n",
            "\n",
            "Comparison:\n",
            "Original: The main action in the video is a woman playing a ukulele on a grassy hillside with rolling hills and trees in the background. She is wearing a white dress and has long, wavy hair.\n",
            "Fine-Tuned: A woman stands on a grassy hill, playing an orange ukulele. She moves her head slightly and adjusts her hair as she plays.\n"
          ]
        }
      ]
    }
  ]
}